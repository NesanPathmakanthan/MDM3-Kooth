import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import normalized_mutual_info_score
import community.community_louvain as community_louvain

# Load the data
file_path = '/Users/isobelbridge/Documents/mdm4/simulated_kooth_data.csv'
df = pd.read_csv(file_path)

# add a month column so can process the data monthly
df['Timestamp'] = pd.to_datetime(df['Timestamp'])
df['Month'] = df['Timestamp'].dt.to_period('M')  # Converts to year-month format 

# Get unique months in the dataset
unique_months = df['Month'].unique()

# function to seperate data into monthly time frames 
def process_time_frame(data_subset, title, plot=False):
    # Calculate topic distributions
    topic_counts = {user_id: {topic: 0 for topic in ["Anxiety", "Depression", "LGBTQ+", "Neurodiversity"]}
                    for user_id in data_subset['Service_User_ID'].unique()}
    for _, row in data_subset.iterrows():
        topic_counts[row['Service_User_ID']][row['Content_Topic']] += 1
    # calculate and normalise topic distributions for each individual user 
    # allows to compare how similar each users posts are
    topic_distributions = {}
    for user_id, counts in topic_counts.items():
        total = sum(counts.values())
        topic_distributions[user_id] = {topic: counts[topic] / total if total > 0 else 0 for topic in counts}
    # for cosine similarity for edge weigtings 
    user_vectors = {user: np.array(list(distribution.values())) for user, distribution in topic_distributions.items()}
    # Build network
    G_user = nx.DiGraph()
    for user_id in data_subset['Service_User_ID'].unique():
        G_user.add_node(user_id)
    # building a directed graph
    for _, row in data_subset.iterrows():
        # checking if current row has an ancestor amnd retrieving it 
        if not pd.isna(row['Ancestor_Content_ID']):
            ancestor_row = data_subset[data_subset['Content_Created_ID'] == row['Ancestor_Content_ID']]
            # double checking that ancestor exsists (stops errors from missing ancestor content)
            if not ancestor_row.empty:
                # extract users for the two pieces of content
                ancestor_user_id = ancestor_row.iloc[0]['Service_User_ID']
                current_user_id = row['Service_User_ID']
                # works out how similar those users content is for edges 
                similarity = cosine_similarity(
                    user_vectors[current_user_id].reshape(1, -1),
                    user_vectors[ancestor_user_id].reshape(1, -1)
                )[0, 0]
                if G_user.has_edge(current_user_id, ancestor_user_id):
                    G_user[current_user_id][ancestor_user_id]['weight'] += similarity
                else:
                    G_user.add_edge(current_user_id, ancestor_user_id, weight=similarity)

    # Subgraph of only connected nodes 
    # we're assuming people with no iteractions dont belong to a community 
    connected_nodes = {node for edge in G_user.edges() for node in edge}
    G_connected = G_user.subgraph(connected_nodes)

    # actual communtiies
    ground_truth = {row['Service_User_ID']: row['Community_ID'] for _, row in data_subset.iterrows() if row['Service_User_ID'] in connected_nodes}
    true_labels = [ground_truth.get(node, -1) for node in G_connected.nodes()]

    # Louvain Community Detection
    louvain_partition = community_louvain.best_partition(G_connected.to_undirected(), weight='weight')
    louvain_labels = [louvain_partition.get(node, -1) for node in G_connected.nodes()]
    louvain_nmi = normalized_mutual_info_score(true_labels, louvain_labels)
    print(f"{title} - Louvain NMI: {louvain_nmi:.4f}")

    # Plot only for the first month
    if plot:
        pos = nx.kamada_kawai_layout(G_connected)
        plt.figure(figsize=(12, 6))

        # Subplot 1: Ground Truth
        plt.subplot(1, 2, 1)
        nx.draw(
            G_connected,
            pos,
            with_labels=True,
            node_color=true_labels,
            cmap=plt.cm.tab10,
            node_size=600,
            edge_color="gray"
        )
        plt.title(f"{title} - Ground Truth", fontsize=14)

        # Subplot 2: Louvain Communities
        plt.subplot(1, 2, 2)
        nx.draw(
            G_connected,
            pos,
            with_labels=True,
            node_color=louvain_labels,
            cmap=plt.cm.tab10,
            node_size=600,
            edge_color="gray"
        )
        plt.title(f"{title} - Louvain Communities", fontsize=14)

        plt.tight_layout()
        plt.show()

# Process each month
for i, month in enumerate(unique_months):
    data_subset = df[df['Month'] == month]
    title = f"Month {month}"
    if i == 0:  # Plot only the first month
        process_time_frame(data_subset, title, plot=True)
    else:  # For all other months, calculate NMI without plotting
        process_time_frame(data_subset, title, plot=False)
